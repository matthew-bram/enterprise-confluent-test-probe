# Test Probe - Core Module Reference Configuration
# Configuration for actor system, supervision, and core services

test-probe.core {
  # Actor System Configuration
  actor-system {
    # Name of the actor system
    name = "test-probe"

    # Timeout for actor ask patterns (25s < HTTP timeout 30s)
    # This ensures ask timeout triggers before HTTP client timeout
    timeout = 25s

    # Shutdown timeout - maximum time to wait for graceful shutdown
    shutdown-timeout = 45 seconds

    # Initialization timeout - maximum time to wait for startup
    initialization-timeout = 30 seconds

    # REST client pool size for load balancing
    pool-size = 3

    # Maximum test execution time before timeout
    max-execution-time = 300 seconds
  }

  # Circuit Breaker Configuration
  # COMMENTED OUT: Not validated by CoreConfigValidator
  # Applied to all actor ask operations for fail-fast behavior
  # circuit-breaker {
  #   # Maximum consecutive failures before opening circuit
  #   max-failures = 5
  #
  #   # Timeout for individual call (should match ask timeout)
  #   call-timeout = 25s
  #
  #   # Time to wait before attempting recovery (half-open state)
  #   reset-timeout = 30s
  # }

  # Supervision Configuration
  supervision {
    # Maximum number of restarts within time range
    max-restarts = 10

    # Time range for restart limit
    restart-time-range = 1 minute
  }

  # Test Execution Configuration
  test-execution {
    # Maximum retry attempts for temporary failures
    max-retries = 3

    # Delay before cleaning up completed tests
    cleanup-delay = 60 seconds

    # Stash buffer size for message stashing during state transitions
    stash-buffer-size = 100
  }

  # State Timers Configuration
  # COMMENTED OUT: Not validated by CoreConfigValidator
  # Explicit timers for each test execution state
  timers {
    # Setup state timeout (time to upload files)
    setup-state = 60 seconds

    # Loading state timeout (time to load test from storage)
    loading-state = 120 seconds

    # Completed state timeout (time before cleanup of successful tests)
    completed-state = 60 seconds

    # Exception state timeout (time before cleanup of failed tests)
    exception-state = 30 seconds
  }

  # Cucumber Configuration
  cucumber {
    # Default glue package for step definitions
    # Framework glue package containing base step definitions
    glue-packages = "io.distia.probe.core.glue"
  }

  # Services timeout for storage, vault, etc.
  services.timeout = 30 seconds

  # Kafka Configuration
  kafka {
    # Bootstrap servers (defaults to localhost for development)
    bootstrap-servers = "localhost:9092"

    # Schema registry URL
    schema-registry-url = "http://localhost:8081"
    schema-registry-url = ${?SCHEMA_REGISTRY_URL}

    # OAuth2 configuration
    oauth {
      token-endpoint = "http://localhost:8080/oauth/token"
      token-endpoint = ${?OAUTH_TOKEN_ENDPOINT}

      client-scope = "kafka.read kafka.write"
      client-scope = ${?OAUTH_CLIENT_SCOPE}
    }
  }

  # DSL Configuration
  # COMMENTED OUT: Not validated by CoreConfigValidator
  dsl {
    # Timeout for ask pattern operations in DSL (produceEvent, fetchConsumedEvent)
    ask-timeout = 3 seconds
  }
}

# Pekko Logging Configuration
# Routes Pekko internal logging to SLF4J (Logback)
# Required for actorSystem.log.info() calls to appear in test output
pekko {
  # Log level for Pekko internal events
  loglevel = "INFO"

  # Log level during actor system startup (before loggers are started)
  stdout-loglevel = "INFO"

  # Use SLF4J for logging (routes to Logback)
  loggers = ["org.apache.pekko.event.slf4j.Slf4jLogger"]

  # Disable default dead letter logging (too verbose)
  log-dead-letters = 10
  log-dead-letters-during-shutdown = off
}

# Pekko Actor System Configuration
# Note: This is at root level (not namespaced) as required by Pekko
pekko.actor {
  # Default dispatcher for actors
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 8
      parallelism-max = 64
    }
    throughput = 5
  }

  # Blocking I/O dispatcher for S3, Vault, etc.
  blocking-io-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 8
    }
    throughput = 1
  }

  # HTTP routes dispatcher (isolated from actor system)
  # Prevents HTTP route processing from blocking actor threads
  http-routes-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 16
    }
    throughput = 1
  }

  # Cucumber execution dispatcher
  # Isolated thread pool for long-running, CPU-intensive Cucumber test execution
  # Each thread handles one complete Cucumber test run (feature loading + scenario execution)
  # Pool size limits max concurrent test executions to prevent resource exhaustion
  cucumber-blocking-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      # Max concurrent Cucumber test executions
      # Small pool: Each test is heavyweight (loads features, parses Gherkin, runs scenarios)
      # Adjust based on: available CPU cores, memory constraints, desired concurrency
      # Recommendation: 2-4 for typical environments (each test may run 30s-5min)
      fixed-pool-size = 4
    }
    # Throughput 1: Each test execution is independent and long-running
    # No benefit to batching messages - one test per thread at a time
    throughput = 1
  }

  # Services dispatcher for blocking service I/O operations
  # Isolated thread pool for blocking CSP function calls (AWS Lambda, Azure Functions, GCP Cloud Functions)
  # and block storage operations (S3, Azure Blob, GCS)
  # Prevents blocking I/O from exhausting actor message processing threads
  # Used by: VaultService (CSP vault invocations), BlockStorageService (S3/Azure/GCS operations)
  services-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      # Pool size for concurrent service operations
      # Calculation: (concurrent tests × topics per test × retry attempts)
      # Example: 4 concurrent tests × 3 topics × 3 retries = 36 potential concurrent calls
      # Set conservatively at 16 to prevent thread exhaustion while allowing parallelism
      # TODO: scala-ninja review in Phase 2 - validate pool size for production load
      # Consider: fixed-pool vs cached-pool based on actual load patterns
      fixed-pool-size = 16
    }
    # Throughput 1: Low latency for individual blocking operations
    # Each blocking call is independent (CSP invocation, S3 upload/download)
    throughput = 1
  }
}

# Pekko Coordinated Shutdown
# Ensures graceful shutdown: HTTP unbind → wait for requests → actor termination
pekko.coordinated-shutdown {
  # Maximum time to wait for each shutdown phase
  default-phase-timeout = 15s

  # Terminate actor system after shutdown completes
  terminate-actor-system = on
}

# Pekko Kafka Consumer Configuration
pekko.kafka.consumer {
  # Time to wait for stream shutdown
  stop-timeout = 30s

  # Kafka consumer poll timeout
  poll-timeout = 50ms

  # Interval between polls
  poll-interval = 50ms

  # Maximum time to wait for graceful shutdown
  wait-close-partition = 500ms

  # CRITICAL: Override default 5s timeouts that were killing the stream
  # These timeouts fire during metadata/position operations, even when idle
  # Default values (5s) were causing stream termination before message processing
  metadata-request-timeout = 30s
  position-timeout = 30s
  offset-for-times-timeout = 30s

  # Kafka consumer session timeout (group coordination)
  # Should be 3x heartbeat interval (default heartbeat = 3s)
  session.timeout.ms = 30000
}
